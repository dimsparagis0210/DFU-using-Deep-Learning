{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiTkYe1TzsqNzJPrvc5LuA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimsparagis0210/DFU-using-Deep-Learning/blob/main/EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet Model Development"
      ],
      "metadata": {
        "id": "4Zu3GhWaOHWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The goal of this BSc thesis is to develop a Deep Learning model for Object Detection. Specifically, the object of the model will be to detect ulcers in Diabetic Foots (DFU)"
      ],
      "metadata": {
        "id": "yVXeL4PcfmLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Dataset from Google drive"
      ],
      "metadata": {
        "id": "N368gZrwYVUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxMYbXYHN_Mq",
        "outputId": "9a546b66-6a70-469e-bf39-eabc87fb44cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define dataset path (adjust if needed)\n",
        "dataset = '/content/drive/MyDrive/DFU_Data_Tensorflow'\n",
        "original = dataset + '/images'\n",
        "trainset = dataset + '/train'\n",
        "testset = dataset + '/test'\n",
        "validset = dataset + '/valid'\n",
        "\n",
        "# List categories (folders)\n",
        "os.listdir('/content')"
      ],
      "metadata": {
        "id": "e9Pwve9ZbKli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13a5021-026b-4cd1-ed52-16de20209111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'my_dir', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0gFDnmUFIeNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "mwqrcdz2IVEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The dataset contains a csv with the annotations' coordinates"
      ],
      "metadata": {
        "id": "ryBIU8XZT1YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define paths to the annotation files\n",
        "train_csv_path = trainset + '/_annotations.csv'\n",
        "test_csv_path = testset + '/_annotations.csv'\n",
        "valid_csv_path = validset + '/_annotations.csv'\n",
        "\n",
        "# Load the CSV files into DataFrames\n",
        "df_train = pd.read_csv(train_csv_path)\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "df_valid = pd.read_csv(valid_csv_path)\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyhjAa4oMa2P",
        "outputId": "7d4a52bb-462b-41a6-820f-f91fa3c568f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filename  width  height  class  \\\n",
            "0  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "1  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "2  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "3     20_jpg.rf.2ae76d51fdf025da6450aaa95081e571.jpg    640     640     bb   \n",
            "4  40152324_676265276071443_3891772576753516544_n...    640     640  Ulcer   \n",
            "\n",
            "   xmin  ymin  xmax  ymax  \n",
            "0    88   115   237   321  \n",
            "1   382   157   523   407  \n",
            "2   594   222   640   425  \n",
            "3   255   190   387   269  \n",
            "4   147   356   235   392  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "id": "lmT7bchFa_z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(image_path, bbox):\n",
        "    # Read the image from disk\n",
        "    image = tf.io.read_file(image_path)\n",
        "    # Decode the image (assuming JPEG format)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # Resize the image to the desired size\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    image = image / 255.0\n",
        "    # Convert bounding box coordinates to float32\n",
        "    bbox = tf.cast(bbox, dtype=tf.float32)\n",
        "    return image, bbox\n"
      ],
      "metadata": {
        "id": "4lvNwVCNVrCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a new dataset in a format that Keras can accept"
      ],
      "metadata": {
        "id": "mJqIDRPRbEbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(df, image_dir):\n",
        "    # Extract image file paths and bounding boxes\n",
        "    image_paths = [os.path.join(image_dir, fname) for fname in df['filename']]\n",
        "    bboxes = df[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
        "\n",
        "    # Create a TensorFlow Dataset from the image paths and bounding boxes\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, bboxes))\n",
        "\n",
        "    # Define a function to load images and parse annotations\n",
        "    def load_image_and_bbox(image_path, bbox):\n",
        "        image, bbox = load_and_preprocess_image(image_path, bbox)\n",
        "        return image, bbox\n",
        "\n",
        "    # Map the function over the dataset\n",
        "    dataset = dataset.map(load_image_and_bbox, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create the datasets\n",
        "train_dataset = create_dataset(df_train, trainset)\n",
        "test_dataset = create_dataset(df_test, testset)\n",
        "valid_dataset = create_dataset(df_valid, validset)"
      ],
      "metadata": {
        "id": "sGm6Ep-SVvPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetching data in separate batches"
      ],
      "metadata": {
        "id": "FnmkvLqQbTZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = valid_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "roxLK1MtVxwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development"
      ],
      "metadata": {
        "id": "Bkf5kkQzbbbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Optimization (Keras-Tuner)"
      ],
      "metadata": {
        "id": "wbc_J5TEbk83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P06-w3ghgsIN",
        "outputId": "65d1940b-62ee-4464-f670-0848aae9ca63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    base_model = EfficientNetB0(include_top=False, input_tensor=inputs, weights='imagenet')\n",
        "    base_model.trainable = hp.Boolean('trainable_base', default=False)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
        "    x = layers.Dense(hp.Int('units', min_value=128, max_value=512, step=64), activation='relu')(x)\n",
        "    outputs = layers.Dense(4, activation='sigmoid')(x)  # Adjust based on your output requirements\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')),\n",
        "        loss='mean_squared_error',  # Adjust based on your task\n",
        "        metrics=['accuracy']  # Adjust based on your task\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "l-qCCE8lXMHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=20,\n",
        "    executions_per_trial=2,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='efficientnet_tuning'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0kzJgs1XgbW",
        "outputId": "a71696d2-0c78-4aa3-88bb-3d56e1dfa8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from hyperparam_tuning/efficientnet_tuning/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_dataset, validation_data=val_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSrnMT7-Xtk1",
        "outputId": "ab4d5bd5-7293-48b4-c30f-ebb69338b54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 05m 03s]\n",
            "val_accuracy: 0.34415584802627563\n",
            "\n",
            "Best val_accuracy So Far: 0.5844155550003052\n",
            "Total elapsed time: 01h 04m 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)"
      ],
      "metadata": {
        "id": "ItLPA0_9b2Gq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}