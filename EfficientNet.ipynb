{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPk4Y7Gdgkj/LBTSrLCRus1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimsparagis0210/DFU-using-Deep-Learning/blob/main/EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet Model Development"
      ],
      "metadata": {
        "id": "4Zu3GhWaOHWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The goal of this BSc thesis is to develop a Deep Learning model for Object Detection. Specifically, the object of the model will be to detect ulcers in Diabetic Foots (DFU)"
      ],
      "metadata": {
        "id": "yVXeL4PcfmLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Dataset from Google drive"
      ],
      "metadata": {
        "id": "N368gZrwYVUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxMYbXYHN_Mq",
        "outputId": "ce79a8fb-1412-45c8-a479-a52fe20c9751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define dataset path (adjust if needed)\n",
        "dataset = '/content/drive/MyDrive/DFU_Data_Tensorflow'\n",
        "original = dataset + '/images'\n",
        "trainset = dataset + '/train'\n",
        "testset = dataset + '/test'\n",
        "validset = dataset + '/valid'\n",
        "\n",
        "# List categories (folders)\n",
        "os.listdir('/content')"
      ],
      "metadata": {
        "id": "e9Pwve9ZbKli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb46c9a-77b6-4721-9b34-943dcbf935be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'drive', 'my_dir', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0gFDnmUFIeNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "mwqrcdz2IVEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The dataset contains a csv with the annotations' coordinates"
      ],
      "metadata": {
        "id": "ryBIU8XZT1YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "annotations = pd.read_csv(trainset + '/_annotations.csv')\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(annotations.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyhjAa4oMa2P",
        "outputId": "cb9cbd63-9764-416a-b6da-28efbeabc334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filename  width  height  class  \\\n",
            "0  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "1  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "2  51814847_548907345629031_1716986440128135168_n...    640     640  Ulcer   \n",
            "3     20_jpg.rf.2ae76d51fdf025da6450aaa95081e571.jpg    640     640     bb   \n",
            "4  40152324_676265276071443_3891772576753516544_n...    640     640  Ulcer   \n",
            "\n",
            "   xmin  ymin  xmax  ymax  \n",
            "0    88   115   237   321  \n",
            "1   382   157   523   407  \n",
            "2   594   222   640   425  \n",
            "3   255   190   387   269  \n",
            "4   147   356   235   392  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique class names\n",
        "class_names = annotations['class'].unique()\n",
        "\n",
        "# Create a mapping from class names to integers\n",
        "class_mapping = {name: index for index, name in enumerate(class_names)}\n",
        "\n",
        "# Apply the mapping to the 'class' column\n",
        "annotations['class'] = annotations['class'].map(class_mapping)\n"
      ],
      "metadata": {
        "id": "9YIs0pWVPmWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Read the image file\n",
        "    image = tf.io.read_file(image_path)\n",
        "    # Decode the image\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # Resize the image\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    image = image / 255.0\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "fH1H9SH4Psp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_function(filename, bbox, label, image_dir):\n",
        "    # Construct the full path to the image file using TensorFlow operations\n",
        "    image_path = tf.strings.join([image_dir, filename], separator=os.sep)\n",
        "    # Load and preprocess the image\n",
        "    image = load_and_preprocess_image(image_path)\n",
        "    # Normalize bounding box coordinates to [0, 1]\n",
        "    bbox = tf.stack(bbox)\n",
        "    return image, {'bbox': bbox, 'label': label}\n",
        "\n",
        "\n",
        "def create_dataset(annotations, image_dir, batch_size=32):\n",
        "    # Extract columns from the DataFrame\n",
        "    filenames = annotations['filename'].values\n",
        "    bboxes = annotations[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
        "    labels = annotations['class'].values\n",
        "    # Create a TensorFlow Dataset from the filenames, bounding boxes, and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, bboxes, labels))\n",
        "    # Map the parse function over the dataset\n",
        "    dataset = dataset.map(lambda f, b, l: parse_function(f, b, l, image_dir))\n",
        "    # Shuffle, batch, and prefetch the dataset\n",
        "    dataset = dataset.shuffle(buffer_size=len(filenames))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Directory containing the images\n",
        "image_dir_train = trainset\n",
        "image_dir_valid = validset\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = create_dataset(annotations, image_dir_train)\n",
        "valid_dataset = create_dataset(annotations, image_dir_valid)"
      ],
      "metadata": {
        "id": "0qPOWSD5Ptq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation Layer"
      ],
      "metadata": {
        "id": "nJ5hYuyuVoDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.models.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "    layers.RandomBrightness(0.1)\n",
        "])"
      ],
      "metadata": {
        "id": "PpsViTEIPB23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the preprocessing steps to the train and validation set"
      ],
      "metadata": {
        "id": "js-RcPMSrNx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_train(image, label):\n",
        "    image = data_augmentation(image)\n",
        "    return image, label\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "X39Bbu-NrSVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "_18XpjPlLFy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNet"
      ],
      "metadata": {
        "id": "h573lmwRTZoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "X-6i3m5UTmzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P06-w3ghgsIN",
        "outputId": "682247d9-1d32-4af3-ede8-5c41f106d795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    inputs = keras.Input(shape=(224, 224, 3))\n",
        "    # Load EfficientNetB0 with ImageNet weights and exclude the top layers\n",
        "    base_model = keras.applications.EfficientNetB0(include_top=False, input_tensor=inputs, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    # Add global pooling layer\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    # Tune the number of units in the dense layer\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    x = layers.Dense(units=hp_units, activation='relu')(x)\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "jzPvX-SioHvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='my_dir',\n",
        "    project_name='efficientnet_tuning'\n",
        ")\n"
      ],
      "metadata": {
        "id": "5oR0_p05oTXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Expand dimensions to match the input shape of the model\n",
        "img_train = tf.expand_dims(img_train, axis=-1)\n",
        "img_test = tf.expand_dims(img_test, axis=-1)\n",
        "\n",
        "# Assuming img_train is your training dataset with shape (num_samples, 28, 28)\n",
        "# Expand dimensions to add the channel axis\n",
        "\n",
        "print(img_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAy4FZQ9Tl0K",
        "outputId": "96cca5fb-3ae2-4b6a-846b-51d5f3e78859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize images to 224x224\n",
        "img_train = tf.image.resize(img_train, [224, 224])  # Shape becomes (num_samples, 224, 224, 1)"
      ],
      "metadata": {
        "id": "k4O0nTrDc4Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If your model expects 3 channels, you can replicate the single channel\n",
        "img_train = tf.image.grayscale_to_rgb(img_train)  # Shape becomes (num_samples, 224, 224, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "XTh1-v7Sc17V",
        "outputId": "ee8c8646-b059-472c-8504-0f4e918c11bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,224,224,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Tile] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a2c83156fd30>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If your model expects 3 channels, you can replicate the single channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrayscale_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape becomes (num_samples, 224, 224, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6001\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6002\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[60000,224,224,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Tile] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(img_train, label_train, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "YBYL6pD6Tpo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)"
      ],
      "metadata": {
        "id": "_8eH2L0rTrbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}